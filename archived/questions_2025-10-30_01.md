# Understanding Check Questions - 2025-10-30

> **Purpose**: Test your understanding of the working MVP. Answer these as if explaining to a colleague who's about to work on the codebase. Don't look at the code while answering - write from memory/understanding. We'll review together and dive deep on any fuzzy areas.

---

## Part 1: Queue Server Fundamentals

### Q1: The Basic Flow
A colleague asks: "I see we have a queue server. Walk me through what happens when a user submits a message in the Streamlit UI - from button click to response appearing on screen."

### Q2: Why a Queue?
"Why did we build a queue server instead of having Streamlit talk directly to LM Studio? What problem does the queue solve?"

### Q3: Queue Data Structure
"What actual Python data structure is the queue using? Where does it live? What happens to it if the server restarts?"

---

## Part 2: Async & Concurrency Concepts

### Q4: Async vs Threading
"I see a lot of `async` and `await` in the code. Why did we use async instead of regular threading? What's the difference?"

### Q5: The Event Loop
"Someone mentions 'the event loop' when talking about our async code. What is that? Where is it? How does it relate to our queue worker?"

### Q6: Concurrent Requests
"We tested with 8 browser tabs. How does the system handle 8 requests at once if the queue processes them sequentially? What's actually happening concurrently vs sequentially?"

---

## Part 3: Request Flow & Data Structures

### Q7: Request Lifecycle
"Trace a single request through the system. What are the key stages/states it goes through from submission to completion? Where is the request data stored at each stage?"

### Q8: Request ID
"Every request gets a request_id. Why? What do we use it for? What would break if we didn't have it?"

### Q9: Status Tracking
"How does the frontend know where it is in the queue? How does it know when its request is being processed vs complete?"

---

## Part 4: Streaming & Server-Sent Events (SSE)

### Q10: What is SSE?
"The code uses Server-Sent Events for streaming. Explain what SSE is to someone who's only used regular HTTP requests. What makes it different?"

### Q11: The Streaming Flow
"Walk through how a token generated by LM Studio makes it to the user's browser. What format is it in at each step? What's converting it between formats?"

### Q12: Why Streaming?
"We could have just waited for the whole response and sent it back at once. Why stream instead? What are the trade-offs?"

---

## Part 5: Frontend Integration

### Q13: Streamlit Connection
"How does `streamlit_v2.0.py` connect to the queue server? What endpoints does it hit? In what order?"

### Q14: Session State
"What's stored in Streamlit's session state? Why do we need it? What would happen if we didn't use session state?"

### Q15: Queue Position Feedback
"The UI shows 'Joined queue at position X, Y total generations in queue.' Where does that data come from? How does the frontend get it?"

---

## Part 6: Design Decisions & Trade-offs

### Q16: In-Memory Queue
"Our queue is in-memory (not in a database). What do we gain? What do we lose? When would we need to switch to a database?"

### Q17: Worker Pattern
"Describe the 'worker' in queue_server.py. What is it? When does it start? What is it doing when the queue is empty?"

### Q18: Single vs Multiple Workers
"Right now we have one worker processing the queue. Could we have multiple workers? Why or why not? What would we need to change?"

---

## Part 7: Error Handling & Edge Cases

### Q19: LM Studio Down
"What happens if LM Studio is running but the model isn't loaded? What happens if LM Studio crashes mid-generation? Where in the code does each get handled?"

### Q20: Timeout Scenario
"We have timeout handling. Explain when a timeout occurs, what happens to the request, and what the user sees."

### Q21: Abandoned Requests
"A user submits a request, then closes their browser tab. What happens to that request in the queue? Should we handle this differently?"

---

## Part 8: Code Organization

### Q22: Key Files
"We have `original_streamlit.py`, `streamlit_v2.0.py`, and `queue_server.py`. Explain the purpose of each and how they relate."

### Q23: Pydantic Models
"The queue server uses Pydantic models. What are they? Why use them instead of plain dictionaries?"

### Q24: Configuration
"Where is configuration stored? (LM Studio URL, model defaults, etc.) How would you change the LM Studio URL without editing multiple files?"

---

## Part 9: The "Why Did We Do It This Way?" Questions

### Q25: FastAPI vs Flask
"Why FastAPI instead of Flask or another framework?"

### Q26: Streamlit Limitations
"What are the limitations of using Streamlit for this? What might make us want to switch to a different frontend later?"

### Q27: OpenAI-Compatible API
"LM Studio uses an 'OpenAI-compatible' API. What does that mean? Why is that useful?"

---

## Scoring Yourself

For each answer, rate yourself honestly:
- ‚úÖ **Solid**: Could explain this to a colleague confidently
- üü° **Fuzzy**: I kinda get it, but couldn't explain clearly
- ‚ùå **Dunno**: No idea or completely wrong

We'll focus our review session on the üü° and ‚ùå areas to get you to ‚úÖ across the board.

---

## After Answering

Create `answers_2025-10-30_01.md` with your responses. Include your confidence rating for each. Then we'll go through them together - I'll either confirm your understanding or we'll dive deep to clarify.

**Remember**: The goal isn't to "pass a test" - it's to find the edges of your understanding so we can fill in the gaps. Fuzzy answers are GOOD - they tell us where to focus!
